write_csv(paste0(here("data_downloads", paste0(Sys.Date(), "_sample_current.csv"))))
---
title: "COVID Wastewater Surveillance for Western Massachusetts"
library(tidyverse)
library(here)
library(lubridate)
library(ggthemes)
library(scales)
library(patchwork)
library(readxl)
library(ggtext)
options(scipen = 999)
source("wva_calculator.R")
source("mytheme.R")
### Download and initial cleaning ----
url_current <- "https://www.mass.gov/doc/wastewater-dashboard-data/download"
url_arch <- "https://www.mass.gov/doc/2023-2024-archived-wastewater-dashboard-data/download"
download.file(url_current, destfile = "sample_current.xlsx", mode = "wb")
download.file(url_arch, destfile = "sample_arch.xlsx", mode = "wb")
raw_sample_current <-
read_excel(path = "sample_current.xlsx", sheet = "Wastewater Testing Data") %>%
rename_all(~ str_to_lower(.)) %>%
rename_all( ~ str_replace_all(., "[ ]", "_")) %>%
mutate(date = ymd(sample_collection_date), source="current") %>%
write_csv(paste0(here("data_downloads", paste0(Sys.Date(), "_sample_current.csv"))))
raw_sample_arch <-
read_excel(path = "sample_arch.xlsx", sheet = "Wastewater Testing Data") %>%
rename_all(~ str_to_lower(.)) %>%
rename_all( ~ str_replace_all(., "[ ]", "_")) %>%
mutate(date = ymd(sample_collection_date), source="arch") %>%
write_csv(paste0(here("data_downloads", paste0(Sys.Date(), "_sample_arch.csv"))))
weights <- read.csv("better_pop_weights_Aug2024.csv") %>%
select(-mgd) %>% rename(pop_weight = users) %>%
mutate(pop_weight = as.numeric(pop_weight))
wmass_counties <- c("Hampden", "Franklin", "Hampshire", "Berkshire")
nvalley_counties <- c("Franklin", "Hampshire")
svalley_counties <- c("Hampden", "Hampshire")
berkshire <- "Berkshire"
### Set time parameter
time_years <- 1
time_months <- time_years * 12
### Prepare the data
full_sample <-
# combine archive and current data
bind_rows(raw_sample_arch %>%
filter(date < min(raw_sample_current$date)),
raw_sample_current %>% select(-respiratory_season)) %>%
# rename columns
rename(
"avg_7d_covid_conc" = '7_day_average_of_sars-cov-2_concentration',
"county" = county_of_sampling_location,
"city_sample" = city_of_sampling_location,
"system" = name_of_sampling_location) %>%
# convert to copies / mL
mutate(avg_7d_covid_conc = avg_7d_covid_conc/1000) %>%
# modify for log-scale axis display by adding small constant to zero values
mutate(avg_7d_covid_conc = ifelse(avg_7d_covid_conc == 0, .01, avg_7d_covid_conc)) %>%
# remove unused rows
select(-c(tester, site_type, 'units_(measuring_concentration)', state_of_sampling_location)) %>%
# reorganize columns
relocate(date) %>% relocate(city_sample, .after = date) %>% relocate(county, .after = date) %>%
# shift to uniform lower case
mutate(city_sample = str_to_lower(city_sample),
# create lowercase version of system for easy join to pop weights
weights_id = str_to_lower(system)) %>%
# add geographical groupings
mutate(
wmass = county %in% wmass_counties,
nvalley = county %in% nvalley_counties,
svalley = county %in% svalley_counties) %>%
# remove extraneous columns
select(date, county, system, avg_7d_covid_conc, weights_id, wmass, nvalley, svalley) %>%
# add population weights
left_join(weights, by = join_by(weights_id == system)) %>%
select(-weights_id) %>%
# calculate population-days as weights for loess fit
# first calculate reporting interval i.e. days til next report for that location
arrange(date, .by=system) %>%
mutate(
interval = ((lead(date, default = max(date)+ddays(1)))-date)/ddays(1), .by=system,
# interval multiplier floor is at 0.5 (for the max of 2 entries in a single day
# ceiling is at 7, so as to not over-weight systems that miss time
pop_day = pop_weight * (min(interval, 7) %>% max(0.5))) %>%
## label runs between gaps for each system
group_by(system) %>%
mutate(
gap = if_else(date > dplyr::lag(date, default=lubridate::origin)+dweeks(2), 1, 0),
run=cumsum(gap),
gap=NULL,
smooth_group = paste0(system, "_", run)) %>% ungroup() %>%
arrange(system, date)
bind_rows(raw_sample_arch %>%
filter(date < min(raw_sample_current$date)),
raw_sample_current %>% select(-respiratory_season)) %>%
# rename columns
rename(
"avg_7d_covid_conc" = '7_day_average_of_sars-cov-2_concentration',
"county" = county_of_sampling_location,
"city_sample" = city_of_sampling_location,
"system" = name_of_sampling_location)
bind_rows(raw_sample_arch %>%
filter(date < min(raw_sample_current$date)),
raw_sample_current
bind_rows(raw_sample_arch %>%
filter(date < min(raw_sample_current$date)),
raw_sample_current %>%
#select(-respiratory_season)) %>%
# rename columns
rename(
"avg_7d_covid_conc" = '7_day_average_of_sars-cov-2_concentration',
"county" = county_of_sampling_location,
"city_sample" = city_of_sampling_location,
"system" = name_of_sampling_location)
bind_rows(raw_sample_arch %>%
filter(date < min(raw_sample_current$date)),
raw_sample_current %>%
#select(-respiratory_season)) %>%
# rename columns
rename(
"avg_7d_covid_conc" = '7_day_average_of_sars-cov-2_concentration',
"county" = county_of_sampling_location,
"city_sample" = city_of_sampling_location,
"system" = name_of_sampling_location)
bind_rows(raw_sample_arch %>%
filter(date < min(raw_sample_current$date)),
raw_sample_current %>%
#select(-respiratory_season)) %>%
# rename columns
rename(
"avg_7d_covid_conc" = '7_day_average_of_sars-cov-2_concentration',
"county" = county_of_sampling_location,
"city_sample" = city_of_sampling_location,
"system" = name_of_sampling_location)
### Prepare the data
full_sample <-
### Prepare the data
full_sample <-
bind_rows(raw_sample_arch %>%
filter(date < min(raw_sample_current$date)),
raw_sample_current)
### Prepare the data
full_sample <-
# combine archive and current data
bind_rows(raw_sample_arch %>%
filter(date < min(raw_sample_current$date)),
raw_sample_current) %>%
#select(-respiratory_season)) %>%
# rename columns
rename(
"avg_7d_covid_conc" = '7_day_average_of_sars-cov-2_concentration',
"county" = county_of_sampling_location,
"city_sample" = city_of_sampling_location,
"system" = name_of_sampling_location) %>%
# convert to copies / mL
mutate(avg_7d_covid_conc = avg_7d_covid_conc/1000) %>%
# modify for log-scale axis display by adding small constant to zero values
mutate(avg_7d_covid_conc = ifelse(avg_7d_covid_conc == 0, .01, avg_7d_covid_conc)) %>%
# remove unused rows
select(-c(tester, site_type, 'units_(measuring_concentration)', state_of_sampling_location)) %>%
# reorganize columns
relocate(date) %>% relocate(city_sample, .after = date) %>% relocate(county, .after = date) %>%
# shift to uniform lower case
mutate(city_sample = str_to_lower(city_sample),
# create lowercase version of system for easy join to pop weights
weights_id = str_to_lower(system)) %>%
# add geographical groupings
mutate(
wmass = county %in% wmass_counties,
nvalley = county %in% nvalley_counties,
svalley = county %in% svalley_counties) %>%
# remove extraneous columns
select(date, county, system, avg_7d_covid_conc, weights_id, wmass, nvalley, svalley) %>%
# add population weights
left_join(weights, by = join_by(weights_id == system)) %>%
select(-weights_id) %>%
# calculate population-days as weights for loess fit
# first calculate reporting interval i.e. days til next report for that location
arrange(date, .by=system) %>%
mutate(
interval = ((lead(date, default = max(date)+ddays(1)))-date)/ddays(1), .by=system,
# interval multiplier floor is at 0.5 (for the max of 2 entries in a single day
# ceiling is at 7, so as to not over-weight systems that miss time
pop_day = pop_weight * (min(interval, 7) %>% max(0.5))) %>%
## label runs between gaps for each system
group_by(system) %>%
mutate(
gap = if_else(date > dplyr::lag(date, default=lubridate::origin)+dweeks(2), 1, 0),
run=cumsum(gap),
gap=NULL,
smooth_group = paste0(system, "_", run)) %>% ungroup() %>%
arrange(system, date)
library(tidyverse)
library(here)
library(lubridate)
library(ggthemes)
library(scales)
library(patchwork)
library(readxl)
library(ggtext)
options(scipen = 999)
source("wva_calculator.R")
source("mytheme.R")
### Download and initial cleaning ----
url_current <- "https://www.mass.gov/doc/wastewater-dashboard-data/download"
url_arch <- "https://www.mass.gov/doc/2023-2024-archived-wastewater-dashboard-data/download"
download.file(url_current, destfile = "sample_current.xlsx", mode = "wb")
download.file(url_arch, destfile = "sample_arch.xlsx", mode = "wb")
raw_sample_current <-
read_excel(path = "sample_current.xlsx", sheet = "Wastewater Testing Data") %>%
rename_all(~ str_to_lower(.)) %>%
rename_all( ~ str_replace_all(., "[ ]", "_")) %>%
mutate(date = ymd(sample_collection_date), source="current") %>%
write_csv(paste0(here("data_downloads", paste0(Sys.Date(), "_sample_current.csv"))))
raw_sample_arch <-
read_excel(path = "sample_arch.xlsx", sheet = "Wastewater Testing Data") %>%
rename_all(~ str_to_lower(.)) %>%
rename_all( ~ str_replace_all(., "[ ]", "_")) %>%
mutate(date = ymd(sample_collection_date), source="arch") %>%
write_csv(paste0(here("data_downloads", paste0(Sys.Date(), "_sample_arch.csv"))))
weights <- read.csv("better_pop_weights_Aug2024.csv") %>%
select(-mgd) %>% rename(pop_weight = users) %>%
mutate(pop_weight = as.numeric(pop_weight))
wmass_counties <- c("Hampden", "Franklin", "Hampshire", "Berkshire")
nvalley_counties <- c("Franklin", "Hampshire")
svalley_counties <- c("Hampden", "Hampshire")
berkshire <- "Berkshire"
### Set time parameter
time_years <- 1
time_months <- time_years * 12
### Prepare the data
full_sample <-
# combine archive and current data
bind_rows(raw_sample_arch %>%
filter(date < min(raw_sample_current$date)),
raw_sample_current) %>%
#select(-respiratory_season)) %>%
# rename columns
rename(
"avg_7d_covid_conc" = '7_day_average_of_sars-cov-2_concentration',
"county" = county_of_sampling_location,
"city_sample" = city_of_sampling_location,
"system" = name_of_sampling_location) %>%
# convert to copies / mL
mutate(avg_7d_covid_conc = avg_7d_covid_conc/1000) %>%
# modify for log-scale axis display by adding small constant to zero values
mutate(avg_7d_covid_conc = ifelse(avg_7d_covid_conc == 0, .01, avg_7d_covid_conc)) %>%
# remove unused rows
select(-c(tester, site_type, 'units_(measuring_concentration)', state_of_sampling_location)) %>%
# reorganize columns
relocate(date) %>% relocate(city_sample, .after = date) %>% relocate(county, .after = date) %>%
# shift to uniform lower case
mutate(city_sample = str_to_lower(city_sample),
# create lowercase version of system for easy join to pop weights
weights_id = str_to_lower(system)) %>%
# add geographical groupings
mutate(
wmass = county %in% wmass_counties,
nvalley = county %in% nvalley_counties,
svalley = county %in% svalley_counties) %>%
# remove extraneous columns
select(date, county, system, avg_7d_covid_conc, weights_id, wmass, nvalley, svalley) %>%
# add population weights
left_join(weights, by = join_by(weights_id == system)) %>%
select(-weights_id) %>%
# calculate population-days as weights for loess fit
# first calculate reporting interval i.e. days til next report for that location
arrange(date, .by=system) %>%
mutate(
interval = ((lead(date, default = max(date)+ddays(1)))-date)/ddays(1), .by=system,
# interval multiplier floor is at 0.5 (for the max of 2 entries in a single day
# ceiling is at 7, so as to not over-weight systems that miss time
pop_day = pop_weight * (min(interval, 7) %>% max(0.5))) %>%
## label runs between gaps for each system
group_by(system) %>%
mutate(
gap = if_else(date > dplyr::lag(date, default=lubridate::origin)+dweeks(2), 1, 0),
run=cumsum(gap),
gap=NULL,
smooth_group = paste0(system, "_", run)) %>% ungroup() %>%
arrange(system, date)
# save(full_sample, weights, file="current.Rda")
wva_pal <- c("#49a667", "#b6c459", "#8fa1ef", "#fdae61", "#f45489")
### -----
### Load data ----
# load("current.Rda")
View(full_sample)
# Generate smooth and wvas
# smooth_operator automaticaly filters for western mass
# we can customize that for future iterations
dfreg <- smooth_operator(full_sample, time_years=1)
thresholds_reg <- wtd_ww_threshold_breaks(dfreg$avg_7d_covid_conc, wts=dfreg$pop_day)
View(dfreg)
View(smooth_operator)
View(raw_sample_arch)
View(full_sample)
View(dfreg)
View(smooth_operator)
df <- full_sample
sample = df %>% filter(date > max(date) - years(time_years) & wmass)
max(df$date)
years(1)
max(df$date)
max(df$date) - years(1)
View(dfreg)
test <- df %>% filter(wmass)
View(test)
sample = df %>% filter(date > max(date) - years(time_years)
sample = df %>% filter(date > max(date) - years(time_years))
View(sample)
sample = df %>% filter(date > (max(date) - years(time_years)))
max(df$date)
max(df$date) - years(1)
test <- df %>% filter(date > "2024-08-25")
test <- df %>% filter(date > "2024-08-25" & wmass)
View(full_sample)
summary(full_sample)
summary(full_sample$date)
library(lubridate)
library(tidyverse)
library(here)
library(lubridate)
library(ggthemes)
library(scales)
library(patchwork)
library(readxl)
library(ggtext)
options(scipen = 999)
source("wva_calculator.R")
source("mytheme.R")
### Download and initial cleaning ----
url_current <- "https://www.mass.gov/doc/wastewater-dashboard-data/download"
url_arch <- "https://www.mass.gov/doc/2023-2024-archived-wastewater-dashboard-data/download"
download.file(url_current, destfile = "sample_current.xlsx", mode = "wb")
download.file(url_arch, destfile = "sample_arch.xlsx", mode = "wb")
raw_sample_current <-
read_excel(path = "sample_current.xlsx", sheet = "Wastewater Testing Data") %>%
rename_all(~ str_to_lower(.)) %>%
rename_all( ~ str_replace_all(., "[ ]", "_")) %>%
mutate(date = ymd(sample_collection_date), source="current") %>%
write_csv(paste0(here("data_downloads", paste0(Sys.Date(), "_sample_current.csv"))))
raw_sample_arch <-
read_excel(path = "sample_arch.xlsx", sheet = "Wastewater Testing Data") %>%
rename_all(~ str_to_lower(.)) %>%
rename_all( ~ str_replace_all(., "[ ]", "_")) %>%
mutate(date = ymd(sample_collection_date), source="arch") %>%
write_csv(paste0(here("data_downloads", paste0(Sys.Date(), "_sample_arch.csv"))))
weights <- read.csv("better_pop_weights_Aug2024.csv") %>%
select(-mgd) %>% rename(pop_weight = users) %>%
mutate(pop_weight = as.numeric(pop_weight))
wmass_counties <- c("Hampden", "Franklin", "Hampshire", "Berkshire")
nvalley_counties <- c("Franklin", "Hampshire")
svalley_counties <- c("Hampden", "Hampshire")
berkshire <- "Berkshire"
### Set time parameter
time_years <- 1
time_months <- time_years * 12
### Prepare the data
full_sample <-
# combine archive and current data
bind_rows(raw_sample_arch %>%
filter(date < min(raw_sample_current$date)),
raw_sample_current) %>%
#select(-respiratory_season)) %>%
# rename columns
rename(
"avg_7d_covid_conc" = '7_day_average_of_sars-cov-2_concentration',
"county" = county_of_sampling_location,
"city_sample" = city_of_sampling_location,
"system" = name_of_sampling_location) %>%
# convert to copies / mL
mutate(avg_7d_covid_conc = avg_7d_covid_conc/1000) %>%
# modify for log-scale axis display by adding small constant to zero values
mutate(avg_7d_covid_conc = ifelse(avg_7d_covid_conc == 0, .01, avg_7d_covid_conc)) %>%
# remove unused rows
select(-c(tester, site_type, 'units_(measuring_concentration)', state_of_sampling_location)) %>%
# reorganize columns
relocate(date) %>% relocate(city_sample, .after = date) %>% relocate(county, .after = date) %>%
# shift to uniform lower case
mutate(city_sample = str_to_lower(city_sample),
# create lowercase version of system for easy join to pop weights
weights_id = str_to_lower(system)) %>%
# add geographical groupings
mutate(
wmass = county %in% wmass_counties,
nvalley = county %in% nvalley_counties,
svalley = county %in% svalley_counties) %>%
# remove extraneous columns
select(date, county, system, avg_7d_covid_conc, weights_id, wmass, nvalley, svalley) %>%
# add population weights
left_join(weights, by = join_by(weights_id == system)) %>%
select(-weights_id) %>%
# calculate population-days as weights for loess fit
# first calculate reporting interval i.e. days til next report for that location
arrange(date, .by=system) %>%
mutate(
interval = ((lead(date, default = max(date)+ddays(1)))-date)/ddays(1), .by=system,
# interval multiplier floor is at 0.5 (for the max of 2 entries in a single day
# ceiling is at 7, so as to not over-weight systems that miss time
pop_day = pop_weight * (min(interval, 7) %>% max(0.5))) %>%
## label runs between gaps for each system
group_by(system) %>%
mutate(
gap = if_else(date > dplyr::lag(date, default=lubridate::origin)+dweeks(2), 1, 0),
run=cumsum(gap),
gap=NULL,
smooth_group = paste0(system, "_", run)) %>% ungroup() %>%
arrange(system, date)
# save(full_sample, weights, file="current.Rda")
wva_pal <- c("#49a667", "#b6c459", "#8fa1ef", "#fdae61", "#f45489")
### -----
### Load data ----
# load("current.Rda")
# Generate smooth and wvas
# smooth_operator automaticaly filters for western mass
# we can customize that for future iterations
dfreg <- smooth_operator(full_sample, time_years=1)
thresholds_reg <- wtd_ww_threshold_breaks(dfreg$avg_7d_covid_conc, wts=dfreg$pop_day)
### DEBUGGING
df <- full_sample
max(df$date)
format(df$date)
max(df$date) - years(1)
years(1)
max(df$date)
df$maxdate <- max(df$date)
df$cutoff <- max(df$date) - years(1)
View(df)
df %>% filter(date > cutoff)
df %>% filter(date > cutoff & wmass)
df %>% filter(date > cutoff & wmass) %>% View
df %>% filter(date > cutoff) %>% View
table(df$date > df$cutoff)
df %>% filter(wmass) %>% View
df %>% filter(wmass) %>% arrange(desc(date)) %>% View
### DEBUGGING
df <- full_sample
df %>% filter(wmass) %>% arrange(desc(date)) %>% View
View(raw_sample_current)
View(raw_sample_arch)
full_sample %>% filter(wmass) %>% mutate(year = year(date), month = month(date))
full_sample %>% filter(wmass) %>% mutate(year = year(date), month = month(date)) %>%
ggplot() +
geom_bar(aes(month)) %>% facet_wrap(~year, ncol=1)
full_sample %>% filter(wmass) %>%
mutate(year = year(date), month = month(date)) %>%
ggplot() +
geom_bar(aes(month)) +
facet_wrap(~year, ncol=1)
full_sample %>% filter(wmass) %>%
mutate(year = year(date), month = month(date)) %>%
ggplot() +
geom_bar(aes(as.factor(month))) +
facet_wrap(~year, ncol=1)
full_sample %>% filter(wmass) %>%
mutate(year = year(date), month = month(date)) %>%
filter(year > 2022) %>%
ggplot() +
geom_bar(aes(as.factor(month))) +
facet_wrap(~year, ncol=1)
full_sample %>%
# filter(wmass) %>%
mutate(year = year(date), month = month(date)) %>%
filter(year > 2022) %>%
ggplot() +
geom_bar(aes(as.factor(month))) +
facet_wrap(~year, ncol=1)
Sys.setenv(RSTUDIO_PANDOC = "/Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64")
#!/usr/bin/env Rscript
# Load libraries
library(rmarkdown)
# Base path to your repo
base_path <- "/Users/RSF/Library/CloudStorage/Dropbox/My Mac (temp’s MacBook Pro)/Documents/GitHub/western-mass-covid"
# File paths
input_file  <- file.path(base_path, "report.Rmd")   # your .Rmd source
output_file <- "wastewater.html"                    # knitted output file name
output_path <- file.path(base_path, output_file)
# Knit the report directly to wastewater.html in base_path
rmarkdown::render(
input       = input_file,
output_file = output_file,
output_dir  = base_path
)
# Base path to your repo
base_path <- "/Users/RSF/Library/CloudStorage/Dropbox/My Mac (temp’s MacBook Pro)/Documents/GitHub/western-mass-covid"
# File paths
input_file  <- file.path(base_path, "wastewater_report.Rmd")   # your .Rmd source
output_file <- "wastewater.html"                    # knitted output file name
output_path <- file.path(base_path, output_file)
# Knit the report directly to wastewater.html in base_path
rmarkdown::render(
input       = input_file,
output_file = output_file,
output_dir  = base_path
)
# Archive copy with date-stamped name
today <- Sys.Date()
archive_dir  <- file.path(base_path, "archive")
archive_file <- file.path(archive_dir, paste0("wastewater-", today, ".html"))
file.copy(output_path, archive_file, overwrite = TRUE)
# Docs copy for GitHub Pages
docs_file <- file.path(base_path, "docs/wastewater.html")
file.copy(output_path, docs_file, overwrite = TRUE)
# Git commit & push
setwd(base_path)
system("git add docs/wastewater.html")
system(paste("git add", archive_file))
Sys.setenv
Sys.setenv(RSTUDIO_PANDOC = "/Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/aarch64")
system(paste("git add", archive_file))
system(paste("git add", shQuote(archive_file)))
system('git commit -m "Automated wastewater report update"')
system("git push")
